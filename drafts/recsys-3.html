<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>  Sistemas recomendadores, parte 3 | On the shoulders of giants
</title>
  <link rel="canonical" href="/drafts/recsys-3.html">

    <link rel="apple-touch-icon" href="/apple-touch-icon.png" sizes="180x180">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="manifest" href="/manifest.json">
    <meta name="theme-color" content="#333333">

  <link rel="stylesheet" href="/theme/css/bootstrap.min.css">
  <link rel="stylesheet" href="/theme/css/font-awesome.min.css">
  <link rel="stylesheet" href="/theme/css/pygments/monokai.min.css">
  <link rel="stylesheet" href="/theme/css/theme.css">

  
  <meta name="description" content="Tercera parte de sistemas recomendadores">


</head>

<body>
  <header class="header">
    <div class="container">
<div class="row">
  <div class="col-sm-12">
    <h1 class="title"><a href="/">On the shoulders of giants</a></h1>
      <p class="text-muted">Diego Quintana's blog</p>
      <ul class="list-inline">
            <li class="list-inline-item"><a href="/pages/about.html">About</a></li>
            <li class="list-inline-item"><a href="/pages/now.html">Now</a></li>
            <li class=" list-inline-item text-muted">|</li>
          <li class="list-inline-item"><a class="fa fa-github" href="https://github.com/diegoquintanav" target="_blank"></a></li>
          <li class="list-inline-item"><a class="fa fa-linkedin" href="https://www.linkedin.com/in/diego-quintana-valenzuela/" target="_blank"></a></li>
          <li class="list-inline-item"><a class="fa fa-stack-overflow" href="https://stackoverflow.com/users/5819113/bluesmonk" target="_blank"></a></li>
          <li class="list-inline-item"><a class="fa fa-envelope" href="mailto:daquintanav@gmail.com" target="_blank"></a></li>
      </ul>
  </div>
</div>    </div>
  </header>

  <div class="main">
    <div class="container">
      <h1>  Sistemas recomendadores, parte 3
</h1>
      <hr>
  <article class="article">
    <header>
      <ul class="list-inline">
        <li class="list-inline-item text-muted" title="2017-10-29T18:01:00-06:00">
          <i class="fa fa-clock-o"></i>
          dom 29 octubre 2017
        </li>
        <li class="list-inline-item">
          <i class="fa fa-folder-open-o"></i>
          <a href="/category/recommender-systems.html">Recommender Systems</a>
        </li>
          <li class="list-inline-item">
            <i class="fa fa-files-o"></i>
              <a href="/tag/recommender-systems.html">#recommender systems</a>,               <a href="/tag/recsys.html">#recsys</a>          </li>
      </ul>
    </header>
    <div class="content">
      <!-- Modified: 2010-12-05 19:30 -->

<h1><em>previously</em></h1>
<p>En la <a href="/drafts/recsys-2.html">parte 2</a> se vieron algunas clasificaciones de SR, con algo más de detalle en aquellos basados en memoria y basados en modelos. Otras clasificación que se mencionó es la de aquellos SR basados en contenido</p>
<h2>Sistemas recomendadores basados en contenido</h2>
<p>Existen elementos que son cuantificables de manera directa, i.e.</p>
<ol>
<li>Popularidad</li>
<li>Género</li>
<li>Director</li>
<li>Ratings</li>
</ol>
<p>Al respecto las recomendaciones sobre estos datos pueden abordarse con SR basados en filtrado colaborativo. Se vio sin embargo que estos SR sufren de algunos problemas debido a la naturaleza poco densa de los datos en el contexto de recomendación y del <em>new item problem</em>, entre otros.</p>
<p>Podemos decir también que hay otros elementos que no son cuanntificables directamente y dependen de otras cosas, por ejemplo el contexto</p>
<ol>
<li>Título de una película</li>
<li>Descripciones de un evento</li>
</ol>
<p>Si existen descripciones suficientes es posible generar recomendaciones a partir del análisis de contenido, lo que abre las posibilidades del uso de otras técnicas tales como el análisis de texto (En python existen dos
herramientas para esto, <a href="www.nltk.org">NLTK</a> y <a href="https://spacy.io/">Spacy</a>), inferencia estadística, entre otras.</p>
<!-- slide 4/25 -->

<p>Los componentes principales de este tipo de SR son</p>
<ol>
<li>Análisis de contenido</li>
<li>Aprendizaje del perfil de usuario</li>
<li>Filtrado de contenido</li>
</ol>
<p><img alt="cbrs" src="{{" title="/assets/img/cbrs.png&quot; | absolute_url }} &quot;cbrs_process;cbrs_process" /></p>
<p>Estos SR presentan la ventaja de que es más fácil explicar las recomendaciones en función del mismo contenido, sin embargo puede ocurrir lo que se conoce como <em>filter bubble</em>, situación en la que las nuevas recomendaciones terminan siendo muy similares a lo ya consumido. Por ejemplo, si me gusta Harry Potter, puede ocurrir que el SR sólo pueda recomendarme libros de Harry Potter y no de la narrativa fantástica en general.</p>
<h2>Análisis de contenido</h2>
<p>El aspecto más importante de este tipo de SR es su dependencia de la representación del contenido.. De manera más general esto se conoce como <em>information retrieval</em>, y tiene que ver en cómo se extrae información de los datos.</p>
<p>En ese sentido, la forma más inmediata es la de analizar el texto en las descripciones de los ítems que forman parte del dataset</p>
<h3>Análisis de texto</h3>
<h4>Representación vectorial</h4>
<p>La primera representación que se hace del texto es a través de lo que se conoce como <em>bag of words</em>, donde todas las palabras se consideran como instancias de cada palabra, en forma de repeticiones.
Esto a su vez permite otras representaciones, una es VSM o <em>Vector space model</em>. Básicamente se trata de vectorizar términos en función de su aparición en una familia de documentos como por ejemplo</p>
<p><img alt="vsm1" src="{{" title="/assets/img/vsm1.png&quot; | absolute_url }} &quot;vsm1;vsm1" /></p>
<p>Un documento entonces puede representarse como un vector donde cada elemento es la frecuencia de cada palabra del corpus en el documento,</p>
<div class="math">$$v = [f_{1},f_{2},...,f_{n}]$$</div>
<p>donde <span class="math">\(f_{i}\)</span> es la frecuencia de cada palabra. Un vector de palabras, o <em>corpus</em>, para el caso del español por ejemplo, es de aproximadamente 60000 palabras. Estos vectores tienen propiedades geométricas que permiten establecer comparaciones entre ellos.</p>
<p>La frecuencia de las palabras por sí sola en un documento no ayuda necesariamente a establecer similitudes, por ejemplo es muy posible encontrar muchas veces en un documento las palabras <em>él, ella, qué, etcétera</em>, lo que no ayudan mucho. Dos documentos no son necesariamente iguales si tienen relativamente la misma cantidad de veces la palabra <em>qué</em>.</p>
<p>Es por esto que se desarrollan métodos de regularización, el primero es normalizar la frecuencia de los términos, a través de lo que se conoce como TF o <em>term frequency</em></p>
<div class="math">$$\mbox{TF}(\mbox{palabra},\mbox{documento}) = \frac{\mbox{veces que sale la palabra en el documento}}{\mbox{cantidad máxima de veces que sale la palabra en todos los documentos}}$$</div>
<p>Además, si se considera nuevamente como ejemplo la palabra <em>qué</em>, esta no es más importante en un documento si aparece 10000 veces, versus otras palabras que aparecen con menor frecuencia. Para incorporar esto se usan logaritmos</p>
<div class="math">$$
\left\{\begin{aligned}
&amp; 1+\log_{10} \mbox{TF}_{p,d} &amp; \mbox{TF}_{p,d} \ge 1\\
&amp; 0 &amp; \mbox{TF}_{p,d} = 0\\
\end{aligned}
\right.$$</div>
<!-- slide 8 -->

<p>Finalmente combinando ambos elementos, es posible obtener una representación estable a través de TF-IDF
$$</p>
<p><span class="math">\($
Algunas observaciones
*  N es la cantidad de documentos del dataset
*  $n_{p}\)</span> es la cantidad de documentos donde aparece la palabra
*  El valor de <span class="math">\(\log(N/n_{p})\)</span> tiende a cero cuando la palabra aparece en muchos documentos (por ejemplo artículos, preposiciones, etc.)</p>
<h4>Representación semántica del contenido</h4>
<p>El texto visto como <em>bag of words</em> pierde sentido contextual, es decir la vectorización no incorpora semántica en las recomendaciones. El contexto en sí mismo añade una nueva capa al análisis de texto, y entre las formas de incorporarlo  se pueden usar <em>ontologías</em>. La <a href="https://en.wikipedia.org/wiki/Semantic_Web">web semántica</a> intenta modelar los contenidos de internet a través de estructuras ontológicas estandarizadas llamadas <a href="https://en.wikipedia.org/wiki/Resource_Description_Framework">RDF</a></p>
<h4>Métricas de similitud</h4>
<p>La vectorización de documentos permite operaciones geométricas y en consecuencia es posible establecer métricas de distancia entre ellos. Las más conocidas ya se han visto y corresponden a</p>
<ul>
<li>Distancia euclidiana</li>
<li>Distancia coseno</li>
</ul>
<p>Sin embargo, los <em>corpus</em> como se vio son de alta dimensionalidad, (60000 palabras para el español, por ejemplo) donde la maldición de la dimensionalidad se presenta nuevamente como un problema. Al respecto, si se normalizan todos los vectores, es posible obtener mejores resultados con la distancia coseno.</p>
<p>Las métricas posibles incluyen <a href="https://dl.acm.org/citation.cfm?doid=1639714.1639757">OKAPI BM25</a> entre otras.
<!-- Slide 14 --></p>
<!-- * (k1+1), k1 es una constante que hay que ajustar -->

<!-- * Ld es el largo del documento -->

<!-- * Lave es el largo promedio de todos los documentos -->

<!-- * Ojo con TFq vs TFd, donde q es para la frecuencia del término en la *query* versus el documento -->

<p>Puede ocurrir que dos palabras son iguales pero tienen distintos significados, lo que complica las comparaciones. Al respecto existen técnicas como</p>
<ul>
<li><em>Latent semantic Indexing</em></li>
<li><em>Latent dirichlet allocation</em></li>
</ul>
<h4>Técnicas de procesamiento adicionales</h4>
<p>El análisis de texto presenta otro tipo de problemas, por ejemplo palabras mal escritas, calidad del texto, etcétera. Algunas técnicas auxiliares usadas en el procesamiento de texto son</p>
<ul>
<li>Normalización i.e. pasar todo a minúsculas o mayúsculas</li>
<li>Tokenizatión: Dividir una oración en unidades, i.e. <em>tokens</em>. La tokenización depende de cada implementación.</li>
<li><em>Stemming</em>: Tomar la raíz o <em>stem</em> de las palabras que compartan una semántica i.e <em>auto</em> en <em>Automovilismo</em> y <em>Autopista</em></li>
<li><em>Porter</em>: Stem de las primeras letras que se repiten.</li>
<li><em>Krovetz</em>: Stem, pero asociada a una palabra existente.</li>
<li>Lemmatization: Una variante de <em>stemming</em> que incorpora el análisis morfológico del texto. Ver más información <a href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html">aquí</a></li>
</ul>
<h2>A continuación</h2>
<p>En la <a href="{{ site.baseurl }}{% post_url 2017-11-08-sysrec-4 %}">parte 4</a> se verán</p>
<ul>
<li>Sistemas recomendadores híbridos</li>
<li>Métricas de calidad en sistemas recomendadores
$$</li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
    </div>
  </article>
    </div>
  </div>

  <footer class="footer">
    <div class="container">
<div class="row">
  <ul class="col-sm-6 list-inline">
    <li class="list-inline-item"><a href="/archives.html">Archives</a></li>
    <li class="list-inline-item"><a href="/categories.html">Categories</a></li>
      <li class="list-inline-item"><a href="/tags.html">Tags</a></li>
  </ul>
  <p class="col-sm-6 text-sm-right text-muted">
    Generated by <a href="https://github.com/getpelican/pelican" target="_blank">Pelican</a>
    / <a href="https://github.com/nairobilug/pelican-alchemy" target="_blank">&#x2728;</a>
  </p>
</div>    </div>
  </footer>
</body>

</html>