---
layout: post
title:  "Sistemas recomendadores, parte 2"
date:   2017-10-28 20:01:00 -0600
categories: sysrec
---
<!-- entry 2, clase al 18.10 -->

*[Actualizado al 5.11.2017]*

## Introducción

En la [parte 1]({{ site.baseurl }}{% post_url 2017-10-28-sysrec-1 %}) se vieron varios aspectos elementales de los sistemas recomendadores. El concepto del error, la definición ~~matemática~~ de una recomendación, y la necesidad que cubren estos sistemas. Mencionamos [este paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.423.5258&rep=rep1&type=pdf) que es mucho más riguroso incluso. La idea ahora es introducir algunos conceptos generales sobre los tipos de sistemas recomendadores. 

## Tipos de clasificaciones

En general es posible delimitar el uso de clasificadores según sus características. Esto suena muy vago al principio, aunque [este post](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.702.4429&rep=rep1&type=pdf) presenta algunas directrices. 

Los sistemas recomendadores (o *SR*) pueden clasificarse en

### En base a el agente que *controla* el SR

1.  Sistemas customizados
1.  Sistemas personalizados

La diferencia aquí es que el primero es aquel en que el usuario modifica su perfil manualmente en base a sus preferencias, mientras que en el segundo es la implementación del SR que crea y actualiza el perfil para cada usuario, con control explícito mínimo del usuario e incluso nulo.

### Memory based *versus* Model based

Edité esta entrada para incorporar este elemento, que había pasado por alto en primer lugar. Esta clasificación es más primitiva, y básicamente se refiere a que aquellos SR *basados en memoria* son aquellos que **usan datos** i.e clicks, ratings, votos, etc. y establecen una métrica de similitud entre usuarios o ítems. Estas métricas pueden ser de diversos tipos, entre las cuales conviene mencionar

*  Similitud coseno
*  Correlación de pearson
*  Distancia euclidiana

Estas recomendaciones permiten unir a ciertas personas o ítems. Si consideramos una matriz $$M$$ donde los usuarios son una dimensión y los ítems otra, los SR basados en memoria representan similitud usando dos vectores de esa matriz i.e. entre dos usuarios o dos ítems. Este tipo de modelos presentan algunos problemas debido a las características de $$M$$, como por ejemplo

1.  El tamaño de $$M$$ es muy grande i.e. La cantidad de datos es masiva, por lo que algunos algoritmos que operan sobre todo $$M$$ se vuelven costosos (Como se verá en KNN más adelante)
1.  Densidad de datos: No todos los items o usuarios tienen información i.e. un usuario por lo general no vota en todas las películas de IMDB, sino que sólo en aquellas que le interesan. Esto genera vectores más dispersos o con más elementos vacíos.
1.  *Cold start problem*, que se refiere al problema de los requerimientos iniciales de poblar (completar) $$M$$, debido a la de baja cantidad de usuarios y ratings al inicio de una aplicación, lo que también es válido para nuevos usuarios que no han definido sus preferencias o presentan pocos ratings. 

Por el otro lado, los **SR basados en modelos** tratan de lidiar con estos problemas, y se verán más adelante. Algunos de estos SR pueden ser

*  Redes bayesianas
*  Basados en SVD (*Single value decomposition*)
*  Probabilistic latent semantic analysis/indexing


### SR Basados en memoria

#### Basados en reglas (*Rule based*)

Las reglas son por lo general definidas manual y explícitamente en función de los objetivos del SR, por lo que tienden a ser más rígidos y a depender más de conocimiento específico. Esto ocurre mucho en sitios de *e-commerce*, donde los SR reflejan en gran medida los intereses de la compañía.

La gran desventaja de estos SR es que dependen de reglas explícitas, y que alimentan los perfiles en base a la ingesta manual de intereses del usuario. Todo esto incluye un sesgo que aporta poco dinamismo al SR ante nuevos escenarios.

#### Basados en contenido (*Content based*)

La principal característica de este SR es que sus recomendaciones se basan en los ítems que el usuario ha demostrado interés explícito anteriormente (*Add to my wishlist*). Las herramientas que usa este SR por lo general son en base a métricas de similitud, i.e. clasificación, *clustering* o análisis de texto, por ejemplo de las descripciones de productos (El análisis de texto y las métricas de similitud son un mundo aparte, que se verán más adelante). 

Uno de los contras de estos SR es que dependen de los hábitos y gustos de un usuario para poder recomendar nuevos ítems. Esto es más que lógico. *¿Cómo puedo recomendar productosa alguien si no sé qué le gusta?* o *¿Cómo decido qué presentarle primero?* Aparentemente los ítems más novedosos son la mejor elección en estos casos.

#### Filtrado colaborativo (*User based*)

La *crème de la crème*. Apuntan a resolver los problemas presentes en los dos SR anteriores, utilizando los ratings de otros usuarios en la *vecindad* del usuario usando el SR. Tradicionalmente, estos sistemas se dicen *Basados en memoria* (*Memory based*, un término que se considera a veces obsoleto, y que a veces es reemplazado por *User based* o *Item based*), o dicho de otra forma, necesitan tener en memoria los intereses de todos los usuarios para emitir una recomendación. Un ejemplo de esto es el algoritmo de $$ k $$ vecinos cercanos o **KNN** (*K Nearest Neighbors*).

##### K *Nearest neighbors*

La idea de KNN es, en términos simples:

> Para un subconjunto de usuarios $$ \mathcal{U} \in U $$, encuentra los ratings para un item $$ i \in I $$ sobre los primeros $$ k $$ usuarios (vecinos en este contexto) que sean *objetivamente* similares a un usuario $$ u \in \mathcal{U} $$.

Lo de *objetivamente similar* requiere atención. ¿Cómo logramos evaluar una similitud *objetivamente*?. Medimos la distancia entre dos objetos y vemos si la distancia es lo suficientemente pequeña. Esto se puede conseguir generalmente a través de una distancia euclidiana o coseno. [Esta página tiene algunas definiciones sobre esto, y presenta algunos ejemplos usando Python](https://blog.dominodatalab.com/recommender-systems-collaborative-filtering/).

Con otra alguna definición *algo más rigurosa*, decimos que el *rating* de un usuario sobre un item a predecir, es la suma ponderada de los *ratings* de otros $$ k $$ usuarios sobre el mismo ítem que comparten similitud.

$$ R(u,i) = \bar{r}_u + \alpha \sum_{j=1}^{k} w(u,j)(r_{j,i}-\bar{r}_j) $$

donde $$ \alpha $$ es un elemento de *regularización*, $$ \bar{r}_u $$ es el promedio de votos del usuario $$ u $$, $$ (r_{j,i}-\bar{r}_j) $$ es el voto de cada usuario o vecino sobre el ítem $$ i $$ menos el promedio de sus votos, y $$ w(u,j) $$ es una función que asigna un peso a cada una de estas valoraciones. Algunas variaciones de  $$ w $$ incluyen la clásica distancia Euclidiana, *Correlación de Pearson* o *Similitud coseno* (Más sobre esto adelante).

Aún así estos modelos sufren de sus propios problemas. El principal problema es de que el cálculo de cada *recomendación* requiere recorrer todos los usuarios en $$ \mathcal{U} $$ cada vez para poder establecer la vecindad de $$u$$. Esto es costoso, y asumiendo que se requiere almacenar en memoria todas las distancias o valores de $$w$$, este algoritmo se vuelve difícil de escalar. 

Además, para modelos más complejos en que la preferencia de cada usuario sobre algún ítem se modela sobre varios parámetros, ocurre algo que se llama la *dimensión de la dimensionalidad* (Más en el anexo).

## Anexo: Curse of dimensionality

![curse-of-dimenzinality]({{ "/assets/curse-of-dimensionality.png" | absolute_url }} "omg" )

Básicamente se trata de lo siguiente: Mientras más características tengan los vectores usados en la modelación de un ítem o recomendación, la distancia entre dos elementos **pierde significancia**.

Suponiendo un espacio de características de $$ d $$ dimensiones se tiene que la **proporción** entre la distancia de cualquier punto dentro de ese espacio hacia el centroide de dicho espacio (o donde se concentra la mayor cantidad de elementos) y hacia otro punto (el que queremos comparar) dentro del mismo espacio se diluye a $$0$$ *en el infinito* o dicho de otra forma, ambas distancias se vuelven relativamente similares. Esto debido a cómo se distribuyen los elementos dentro de un *hipercubo* de $$ d $$ dimensiones, y su *hiperesfera*  inscrita.	

*The curse of dimensionality* es un tema recurrente en este tipo de problemas, y me limitaré a recorrer algunas lecturas muy completas sobre el tema:


*  [*Explain Like I am Five Years Old*](https://stats.stackexchange.com/questions/169156/explain-curse-of-dimensionality-to-a-child) tiene una versión muy simple del problema. 
> *Si debes elegir qué galletas te gustan de un camión de galletas en base al sabor, y asumiendo que hay cuatro tipos de sabores (dulce, salado, ácido, amargo), bastaría con encontrar 4 tipos de galletas diferentes para saber cuál te gusta más. Si a esto añadimos además una característica de color y asumiendo que sólo hay cuatro colores, entonces tienes que comer 4x4 tipos de galletas distintas. Asumiendo que la descripción de galleta se hace cada vez más compleja, resulta cada vez más difícil saber qué galletas te gustan, y probablemente sufras un dolor de estómago antes de poder decidir.*
*  [Este post]  (https://math.stackexchange.com/questions/346775/confusion-related-to-curse-of-dimensionality-in-k-nearest-neighbor) también es una discusión interesante sobre el tema.
*  [Este blog](https://erikbern.com/2015/10/20/nearest-neighbors-and-vector-models-epilogue-curse-of-dimensionality.html) tiene más información aún ~~además de ahorrarme el tiempo de hacer mi propia imagen~~. 
*  [Este otro post](http://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/) presenta una explicación más detallada, *que también incluye perritos.*

{: style="text-align:center"}
![curse-of-dimenzinality]({{ "/assets/3Dproblem_separated.png" | absolute_url }} "omg, 3D" )


# A continuación
*  *Item based collaborative filtering* en vez de *User based*
*  *Model based* SR
