<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>  Sistemas recomendadores, parte 2 | On the shoulders of giants
</title>
  <link rel="canonical" href="/drafts/recsys-2.html">

    <link rel="apple-touch-icon" href="/apple-touch-icon.png" sizes="180x180">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="manifest" href="/manifest.json">
    <meta name="theme-color" content="#333333">

  <link rel="stylesheet" href="/theme/css/bootstrap.min.css">
  <link rel="stylesheet" href="/theme/css/font-awesome.min.css">
  <link rel="stylesheet" href="/theme/css/pygments/monokai.min.css">
  <link rel="stylesheet" href="/theme/css/theme.css">

  
  <meta name="description" content="Segunda parte de sistemas recomendadores">


</head>

<body>
  <header class="header">
    <div class="container">
<div class="row">
  <div class="col-sm-12">
    <h1 class="title"><a href="/">On the shoulders of giants</a></h1>
      <p class="text-muted">Diego Quintana's blog</p>
      <ul class="list-inline">
            <li class="list-inline-item"><a href="/pages/about.html">About</a></li>
            <li class="list-inline-item"><a href="/pages/now.html">Now</a></li>
            <li class=" list-inline-item text-muted">|</li>
          <li class="list-inline-item"><a class="fa fa-github" href="https://github.com/diegoquintanav" target="_blank"></a></li>
          <li class="list-inline-item"><a class="fa fa-linkedin" href="https://www.linkedin.com/in/diego-quintana-valenzuela/" target="_blank"></a></li>
          <li class="list-inline-item"><a class="fa fa-stack-overflow" href="https://stackoverflow.com/users/5819113/bluesmonk" target="_blank"></a></li>
          <li class="list-inline-item"><a class="fa fa-envelope" href="mailto:daquintanav@gmail.com" target="_blank"></a></li>
      </ul>
  </div>
</div>    </div>
  </header>

  <div class="main">
    <div class="container">
      <h1>  Sistemas recomendadores, parte 2
</h1>
      <hr>
  <article class="article">
    <header>
      <ul class="list-inline">
        <li class="list-inline-item text-muted" title="2017-10-28T20:01:00-06:00">
          <i class="fa fa-clock-o"></i>
          sáb 28 octubre 2017
        </li>
        <li class="list-inline-item">
          <i class="fa fa-folder-open-o"></i>
          <a href="/category/recommender-systems.html">Recommender Systems</a>
        </li>
          <li class="list-inline-item">
            <i class="fa fa-files-o"></i>
              <a href="/tag/recommender-systems.html">#recommender systems</a>,               <a href="/tag/recsys.html">#recsys</a>          </li>
      </ul>
    </header>
    <div class="content">
      <h1><em>Previously</em></h1>
<p>En la <a href="/drafts/recsys-1.html">parte 1</a> se vieron varios aspectos elementales de los sistemas recomendadores. El concepto del error, la definición ~~matemática~~ de una recomendación, y la necesidad que cubren estos sistemas. Mencionamos <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.423.5258&amp;rep=rep1&amp;type=pdf">este paper</a> que es mucho más riguroso incluso. La idea ahora es introducir algunos conceptos generales sobre los tipos de sistemas recomendadores.</p>
<p>En general es posible delimitar el uso de clasificadores según sus características. Esto suena muy vago al principio, aunque <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.702.4429&amp;rep=rep1&amp;type=pdf">este paper</a> presenta algunas directrices.</p>
<p>Los sistemas recomendadores (o <em>SR</em>) pueden clasificarse en</p>
<h2>En base al agente que <em>controla</em> el SR</h2>
<ol>
<li>Sistemas customizados</li>
<li>Sistemas personalizados</li>
</ol>
<p>La diferencia aquí es que el primero es aquel en que el usuario modifica su perfil manualmente en base a sus preferencias, mientras que en el segundo es la implementación del SR que crea y actualiza el perfil para cada usuario, con control explícito mínimo del usuario e incluso nulo.</p>
<h2>En base a la forma que los modelos aprenden</h2>
<p>Esta clasificación es más primitiva, y da lugar a sistemas <em>basados en memoria</em> y sistemas <em>basados en modelos</em>. Los primeros son aquellos que <strong>usan datos</strong> i.e clicks, ratings, votos, etc. y establecen una métrica de similitud entre usuarios o ítems. Estas métricas pueden ser de diversos tipos, entre las cuales conviene mencionar</p>
<ul>
<li>Similitud coseno</li>
<li>Correlación de pearson</li>
<li>Distancia euclidiana</li>
</ul>
<p>Estas recomendaciones permiten unir a ciertas personas o ítems. Si consideramos una matriz <span class="math">\(M\)</span> donde los usuarios son una dimensión y los ítems otra, los SR basados en memoria representan similitud usando dos vectores de esa matriz i.e. entre dos usuarios o dos ítems. Este tipo de modelos presentan algunos problemas debido a las características de <span class="math">\(M\)</span>, como por ejemplo</p>
<ol>
<li>El tamaño de <span class="math">\(M\)</span> es muy grande i.e. La cantidad de datos es masiva, por lo que algunos algoritmos que operan sobre todo <span class="math">\(M\)</span> se vuelven costosos (Como se verá en KNN más adelante)</li>
<li>Densidad de datos: No todos los items o usuarios tienen información i.e. un usuario por lo general no vota en todas las películas de IMDB, sino que sólo en aquellas que le interesan. Esto genera vectores más dispersos o con más elementos vacíos.</li>
<li><em>Cold start</em>, que se refiere al problema de los requerimientos iniciales de poblar (completar) <span class="math">\(M\)</span>, debido a la baja cantidad de usuarios y ratings al inicio de una aplicación,</li>
<li>Esto también es válido para nuevos usuarios que no han definido sus preferencias o presentan pocos ratings.</li>
</ol>
<p>Por el otro lado, los <strong>SR basados en modelos</strong> tratan de completar esta matriz con probabilidades de que un usuario valore positivamente un ítem que no había encontrado antes. Para esto se apoyan en algoritmos de Machine Learning.</p>
<h3>Métricas de similitud</h3>
<h4>Similitud coseno</h4>
<p>Si se consideran dos vectores de dimensionalidad <span class="math">\(m\)</span>, se define la similitud entre ambos a través del cálculo del <em>coseno</em> del ángulo entre ambos vectores. Formalmente, Si consideramos la matriz <span class="math">\(M\)</span> de <span class="math">\(m\)</span> usuarios y <span class="math">\(n\)</span> items, la similitud entre dos elementos está dada por</p>
<div class="math">$$sim(i,j) = \cos (\vec{i},\vec{j}) = \frac{\vec{i} \cdot \vec{j}}{ { \lVert \vec{i} \rVert }_{2} \ast { \lVert \vec{j} \rVert }_{2} }$$</div>
<h4>Correlación de Pearson</h4>
<p>Una métrica de similitud se obtiene a través de la correlación de Pearson, aislando los casos donde ocurra <em>co-validación</em> i.e. aquellos casos en que el usuario ha validado ítems <span class="math">\(i\)</span> y <span class="math">\(j\)</span> (ver imagen, obtenida del paper).</p>
<div class="math">$$sim(i,j) = \frac{ \sum_{u \in \mathcal{U}}(r_{u,i}-\bar{r}_{i})(r_{u,j}-\bar{r}_{j}) }{ \sqrt{\sum_{u \in \mathcal{U}}(r_{u,i}-\bar{r}_{i})^2} \sqrt{\sum_{u \in \mathcal{U}}(r_{u,i}-\bar{r}_{j})^2} }$$</div>
<p>Donde <span class="math">\(r_{u,j}\)</span> es el rating del usuario <span class="math">\(u\)</span> sobre el ítem <span class="math">\(j\)</span> y <span class="math">\(\bar{r}_{j}\)</span> es el <em>rating</em> promedio sobre el otro ítem.</p>
<p><img alt="IB-CF1" src="/images/CF-IB_1.png" title="IB-CF" /></p>
<h4>Similitud coseno ajustada</h4>
<p>Se obtiene incorporando el promedio <span class="math">\(\bar{r}_{u}\)</span> de votos de cada usuario en el cálculo de similitud, es decir</p>
<div class="math">$$sim(i,j) = \frac{ \sum_{u \in \mathcal{U}}(r_{u,i}-\bar{r}_{u})(r_{u,j}-\bar{r}_{u}) }{ \sqrt{\sum_{u \in \mathcal{U}}(r_{u,i}-\bar{r}_{u})^2} \sqrt{\sum_{u \in \mathcal{U}}(r_{u,i}-\bar{r}_{u})^2} }$$</div>
<p>De los tres métodos indicados, es esta noción de similitud la que obtiene mejores resultados</p>
<p><img alt="IB-CF2" src="/images/similarities.png" title="Similarities comparison" /></p>
<h2>Otra clasificación</h2>
<p>Generalmente, sin embargo, los SR se dividen en cuatro grandes grupos, basados en el tipo de datos de entrada que utilizan, la forma en que construyen perfiles de usuario y los métodos algorítmicos usados para producir recomendaciones.</p>
<h3>Basados en reglas (<em>Rule based</em>)</h3>
<p>Las reglas son por lo general definidas manual y explícitamente en función de los objetivos del SR, por lo que tienden a ser más rígidos y a depender más de conocimiento específico. Esto ocurre mucho en sitios de <em>e-commerce</em>, donde los SR reflejan en gran medida los intereses de la compañía.</p>
<p>La gran desventaja de estos SR es que dependen de reglas explícitas, y que alimentan los perfiles en base a la ingesta manual de intereses del usuario. Todo esto incluye un sesgo que aporta poco dinamismo al SR ante nuevos escenarios.</p>
<h3>Basados en contenido (<em>Content based</em>)</h3>
<p>La principal característica de este SR es que sus recomendaciones se basan en los ítems que el usuario ha demostrado interés explícito anteriormente (<em>Add to my wishlist</em>). Las herramientas que usa este SR por lo general son en base a métricas de similitud, i.e. clasificación, <em>clustering</em> o análisis de texto, por ejemplo de las descripciones de productos (El análisis de texto y las métricas de similitud son un mundo aparte, que se verán más adelante).</p>
<p>Uno de los contras de estos SR es que dependen de los hábitos y gustos de un usuario para poder recomendar nuevos ítems, lo que produce una burbuja. Este problema ocurre a que <em>¿Cómo puedo recomendar productos nuevos a alguien si no sabe que existen?</em> o <em>¿Cómo decido qué nuevos productos presentarle primero?</em> Aparentemente los ítems más novedosos son la mejor elección en estos casos.</p>
<h3>Filtrado colaborativo (<em>User based</em>)</h3>
<p>Apuntan a resolver los problemas presentes en los dos SR anteriores, utilizando los datos como clicks y ratings de otros usuarios en la <em>vecindad</em> del usuario usando el SR.</p>
<p>Tradicionalmente, estos sistemas se dicen <em>Basados en memoria</em> (<em>Memory based</em>, un término que se considera a veces obsoleto, y que a veces es reemplazado por <em>User based</em> o <em>Item based</em>), o dicho de otra forma, necesitan tener la información de los intereses de todos los usuarios para establecer patrones y emitir una recomendación. Un ejemplo de un algoritmo muy usado en <em>clustering</em> esto es el algoritmo de <span class="math">\(k\)</span> vecinos cercanos o <strong>KNN</strong> (<em>K Nearest Neighbors</em>).</p>
<p>Un problema que presentan estos SR es que operan sobre datasets por lo general con poca información. Por ejemplo digamos que un usuario puede haberse manifestado sobre dos productos en un conjunto de 1000 productos. El vector de ratings para este usuario sería de la forma</p>
<div class="math">$$x_{i} = {0,...,r_{34},r_{35},...,0}$$</div>
<p>donde <span class="math">\(r_{34}\)</span> y <span class="math">\(r_{35}\)</span> serían dos votaciones. Se tiene entonces que existen 998 ceros que no aportan información alguna, lo que se transforma en recomendaciones de mala calidad al comienzo de la creación de un perfil de usuario. Si consideramos que constantemente se agregan nuevos ítems, este dataset se diluye cada vez más.</p>
<p>Otro problema que existen en este tipo de SR es el <em>new item problem</em>. Cuando un nuevo item es añadido al pool de opciones, no existe en ningún perfil de usuario y el SR no puede recomendárselo a nadie.</p>
<p>Finalmente, uno de los pincipales problemas que presentan estos algoritmos es que no son escalables. Por ejemplo, para el algoritmo KNN la formación de <em>clusters</em> se hace de manera dinámica o <em>online</em>, lo cual presenta problemas si pensamos que la generación de nuevos ratings y productos ocurre a diario con mucha frecuencia.</p>
<p>El filtrado colaborativo puede dividirse en dos grandes grupos, dependiendo sobre cuál es la entidad usada para establecer patrones o <em>clusters</em></p>
<ul>
<li>filtrado colaborativo basado en usuarios</li>
<li>filtrado colaborativo basado en ítems</li>
</ul>
<p>Si se considera la matriz <span class="math">\(M\)</span> indicada anteriormente, donde las filas son usuarios y las columnas ítems, entonces una diferencia fundamental entre estos grupos es el eje sobre el cual se establece la similitud, siendo las filas para el primer caso y las columnas para el segundo.</p>
<p>La importancia de esto es que cada par en el conjunto a calcular corresponde a usuarios distintos. Esto tiene algunas desventajas, como la pérdida de escala entre usuarios i.e. no todos los usarios evalúan el mismo ítem de la misma manera, y este factor se diluye entre todos los usuarios. Una forma de resolver es con la <em>similitud coseno ajustada</em>.</p>
<p>Al respecto existen varios tipos de algoritmos basados en el filtrado colaborativo, y dos ejemplos pueden ser</p>
<ul>
<li><a href="https://arxiv.org/abs/cs/0702144">Slope One</a></li>
<li>FunkSVD, <a href="http://sifter.org/simon/journal/20061211.html">ganador del premio Netflix</a></li>
</ul>
<h4>User Based Collaborative Filtering (UB-CF)</h4>
<p>En términos generales, se puede resumir que</p>
<ol>
<li>La predicción del rating sobre un ítem <span class="math">\(i\)</span> mejora mientras más vecinos <span class="math">\(k\)</span> de un <em>pool</em> de <span class="math">\(n\)</span> elementos de dimensión <span class="math">\(d\)</span> se consideren en el cálculo de similitud.</li>
<li>La complejidad de calcular la distancia a un ejemplo es de <span class="math">\(\mathcal{O}(d)\)</span>\$</li>
<li>La complejidad de calcular la distancia a <span class="math">\(n\)</span> ejemplos es de <span class="math">\(\mathcal{O}(dn)\)</span>\$</li>
<li>Una vez calculadas las <span class="math">\(n\)</span> distancias, la complejidad de recorrer los <span class="math">\(k\)</span> vecinos más cercanos es de <span class="math">\(\mathcal{O}(nk)\)</span>\$</li>
<li>El tiempo total entonces es de <span class="math">\(\mathcal{O}(nd+nk)\)</span>, (o <span class="math">\(\mathcal{O}(ndk)\)</span> <a href="https://stats.stackexchange.com/questions/219655/k-nn-computational-complexity">en función de cómo se recorren los elementos.</a>) lo cual vuelve a KNN un algoritmo costoso cuando <span class="math">\(n\)</span> es lo suficientemente grande.</li>
</ol>
<p>Un SR alternativo al <em>User Based</em> (UB-CF) es la del filtrado colaborativo basado en <strong>ítems</strong>, o <em>Item based collaborative filtering (IB-CF)</em></p>
<h4>Item Based collaborative filtering (IB-CF)</h4>
<p>Nacen de la necesidad de generar recomendaciones más rápidas sobre datasets masivos o más grandes, para los cuales los algoritmos basados en usuario no escalan bien. Estas técnicas analizan primero la matriz de usuarios e ítems <span class="math">\(M\)</span> para identificar relaciones entre diferentes ítems, y a través de éstas computar calcular de manera indirecta nuevas relaciones con los usuarios.
Dicho de otra forma, estos algoritmos exploran las relaciones entre ítems similares, en vez de realizarla sobre usuarios similares. De esta manera las recomendaciones nuevas se logran encontrando ítems similares a otros que el usuario <span class="math">\(u\)</span> ha calificado positivamente. Dado que las relaciones entre ítems es <em>relativamente</em> estática (a diferencia de los gustos de los usuarios, que son más dinámicos), estas recomendaciones tienden a ser más estables en el tiempo.</p>
<p>De la misma manera que en el caso de UB-CF, algunas métricas de similitud pueden ser la <em>correlación entre ítems</em>, o <em>similitud coseno</em>. <a href="http://files.grouplens.org/papers/www10_sarwar.pdf">Este paper</a> Hace una revisión de los métodos indicados, y concluye que este tipo de SR poseen un rendimiento superior, además de proveer mejores recomendaciones que su compañero UB-CF.</p>
<h3>Sistemas híbridos</h3>
<p>Como se indicó en los casos anteriores, los SR basados en contenido y en filtrado colaborativo presentan sus propios problemas . Los sistemas híbridos apuntan a resolver estas limitaciones combinando ambos tipos de SR.</p>
<h2>A continuación</h2>
<p>En la <a href="/recsys-3.html">parte 3</a> se verán los sistemas de recomendación basados en contenido</p>
<h2>Anexo: KNN y la maldición de la dimensionalidad</h2>
<p>(o en inglés, <em>curse of dimensionality</em>)</p>
<h3>K <em>Nearest neighbors</em> (KNN)</h3>
<p>Este algoritmo asiste en la fase de obtención de patrones sobre un dataset de preferencias, estableciendo grupos o <em>clusters</em> de instancias que guardan relación entre sí de acuerdo a una métrica preestablecida. La idea de KNN en el contexto de recomendación es, en términos simples:</p>
<blockquote>
<p>Para un subconjunto de usuarios <span class="math">\(\mathcal{U} \in U\)</span>, encuentra los ratings para un item <span class="math">\(i \in I\)</span> sobre los primeros <span class="math">\(k\)</span> usuarios (vecinos en este contexto) que sean <em>objetivamente</em> similares a un usuario <span class="math">\(u \in \mathcal{U}\)</span>\$.</p>
</blockquote>
<p>¿Pero cómo se logra establecer similitud <em>objetivamente</em>?. Se mide la distancia entre dos objetos y vemos si la distancia es lo suficientemente pequeña. Esto se puede conseguir generalmente a través de una distancia euclidiana o coseno. <a href="https://blog.dominodatalab.com/recommender-systems-collaborative-filtering/">Esta página tiene algunas definiciones sobre esto, y presenta algunos ejemplos usando Python</a>.</p>
<p>Con otra alguna definición <em>algo más rigurosa</em>, decimos que el <em>rating</em> de un usuario sobre un item a predecir, es la suma ponderada de los <em>ratings</em> de otros <span class="math">\(k\)</span> usuarios sobre el mismo ítem que comparten similitud.</p>
<div class="math">$$R(u,i) = \bar{r}_u + \alpha \sum_{j=1}^{k} w(u,j)(r_{j,i}-\bar{r}_j)$$</div>
<p>donde <span class="math">\(\alpha\)</span> es un elemento de <em>regularización</em>, <span class="math">\(\bar{r}_u\)</span> es el promedio de votos del usuario <span class="math">\(u\)</span>, <span class="math">\((r_{j,i}-\bar{r}_j)\)</span> es el voto de cada usuario o vecino sobre el ítem <span class="math">\(i\)</span> menos el promedio de sus votos, y <span class="math">\(w(u,j)\)</span> es una función que asigna un peso a cada una de estas valoraciones.</p>
<h2>Curse of dimensionality</h2>
<p><img alt="curse-of-dimenzionality" src="/images/curse-of-dimensionality.png" title="omgsocursed" /></p>
<p>Básicamente se trata de lo siguiente: Mientras más características tengan los vectores usados en la modelación de un ítem o recomendación, la distancia entre dos elementos <strong>pierde significancia</strong>.</p>
<p>Suponiendo un espacio de características de <span class="math">\(d\)</span> dimensiones se tiene que la <strong>proporción</strong> entre la distancia de cualquier punto dentro de ese espacio hacia el centroide de dicho espacio (o donde se concentra la mayor cantidad de elementos) y hacia otro punto (el que queremos comparar) dentro del mismo espacio se diluye a <span class="math">\(0\)</span> <em>en el infinito</em> o dicho de otra forma, ambas distancias se vuelven relativamente similares. Esto debido a cómo se distribuyen los elementos dentro de un <em>hipercubo</em> de <span class="math">\(d\)</span> dimensiones, y su <em>hiperesfera</em> inscrita.</p>
<p><em>The curse of dimensionality</em> es un tema recurrente en este tipo de problemas, y me limitaré a recorrer algunas lecturas muy completas sobre el tema:</p>
<ul>
<li><a href="https://stats.stackexchange.com/questions/169156/explain-curse-of-dimensionality-to-a-child"><em>Explain Like I am Five Years Old</em></a> tiene una versión muy simple del problema.<blockquote>
<p><em>Si debes elegir qué galletas te gustan de un camión de galletas en base al sabor, y asumiendo que hay cuatro tipos de sabores (dulce, salado, ácido, amargo), bastaría con encontrar 4 tipos de galletas diferentes para saber cuál te gusta más. Si a esto añadimos además una característica de color y asumiendo que sólo hay cuatro colores, entonces tienes que comer 4x4 tipos de galletas distintas. Asumiendo que la descripción de galleta se hace cada vez más compleja, resulta cada vez más difícil saber qué galletas te gustan, y probablemente sufras un dolor de estómago antes de poder decidir.</em></p>
</blockquote>
</li>
<li><a href="https://math.stackexchange.com/questions/346775/confusion-related-to-curse-of-dimensionality-in-k-nearest-neighbor">Este post</a> también es una discusión interesante sobre el tema.</li>
<li><a href="https://erikbern.com/2015/10/20/nearest-neighbors-and-vector-models-epilogue-curse-of-dimensionality.html">Este blog</a> tiene más información aún ~~además de ahorrarme el tiempo de hacer mi propia imagen~~.</li>
<li><a href="http://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/">Este otro post</a> presenta una explicación más detallada, <em>que también incluye perritos.</em></li>
</ul>
<p><img alt="curse-of-dimenzinality" src="/images/3Dproblem_separated.png" title="omgin3D" /></p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
    </div>
  </article>
    </div>
  </div>

  <footer class="footer">
    <div class="container">
<div class="row">
  <ul class="col-sm-6 list-inline">
    <li class="list-inline-item"><a href="/archives.html">Archives</a></li>
    <li class="list-inline-item"><a href="/categories.html">Categories</a></li>
      <li class="list-inline-item"><a href="/tags.html">Tags</a></li>
  </ul>
  <p class="col-sm-6 text-sm-right text-muted">
    Generated by <a href="https://github.com/getpelican/pelican" target="_blank">Pelican</a>
    / <a href="https://github.com/nairobilug/pelican-alchemy" target="_blank">&#x2728;</a>
  </p>
</div>    </div>
  </footer>
</body>

</html>