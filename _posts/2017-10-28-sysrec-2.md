---
layout: post
title:  "Sistemas recomendadores, parte 2"
date:   2017-10-28 20:01:00 -0600
categories: sysrec
---
<!-- entry 2, clase al 18.10 -->

## Introducción

En la [parte 1]({{ site.baseurl }}{% post_url 2017-10-28-sysrec-2 %}) se vieron varios aspectos elementales de los sistemas recomendadores. El concepto del error, la definición ~~matemática~~ de una recomendación, y la necesidad que cubren estos sistemas. Mencionamos [este paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.423.5258&rep=rep1&type=pdf) que es mucho más riguroso incluso. La idea ahora es introducir algunos conceptos generales sobre los tipos de sistemas recomendadores. 

## Tipos de clasificaciones

En general es posible delimitar el uso de clasificadores según sus características. Esto suena muy vago al principio, aunque [este post](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.702.4429&rep=rep1&type=pdf) presenta algunas directrices. 

Los sistemas recomendadores (o *SR*) pueden clasificarse en

### En base a el agente que *controla* el SR

1.  Sistemas customizados
1.  Sistemas personalizados

La diferencia aquí es que el primero es aquel en que el usuario modifica su perfil manualmente en base a sus preferencias, mientras que en el segundo es la implementación del SR que crea y actualiza el perfil para cada usuario, con control explícito mínimo del usuario e incluso nulo.

### En función del tipo de datos usados

#### Basados en reglas (*Rule based*)

Las reglas son por lo general definidas manual y explícitamente en función de los objetivos del SR, por lo que tienden a ser más rígidos y a depender más de conocimiento específico. Esto ocurre mucho en sitios de *e-commerce*, donde los SR reflejan en gran medida los intereses de la compañía.

La gran desventaja de estos SR es que dependen de reglas explícitas, y que alimentan los perfiles en base a la ingesta manual de intereses del usuario. Todo esto incluye un sesgo que aporta poco dinamismo al SR ante nuevos escenarios.

#### Basados en contenido (*Content based*)

La principal característica de este SR es que sus recomendaciones se basan en los ítems que el usuario ha demostrado interés explícito anteriormente (*Add to my wishlist*). Las herramientas que usa este SR por lo general son en base a métricas de similitud, i.e. clasificación, *clustering* o análisis de texto, por ejemplo de las descripciones de productos (El análisis de texto y las métricas de similitud son un mundo aparte, que se verán más adelante). 

Uno de los contras de estos SR es que dependen de los hábitos y gustos de un usuario para poder recomendar nuevos ítems. Esto es más que lógico. *¿Cómo puedo recomendar productosa alguien si no sé qué le gusta?* o *¿Cómo decido qué presentarle primero?* Aparentemente los ítems más novedosos son la mejor elección en estos casos.


#### Filtrado colaborativo (*User based*)

La *crème de la crème*. Apuntan a resolver los problemas presentes en los dos SR anteriores, utilizando los ratings de otros usuarios en la *vecindad* del usuario usando el SR. Tradicionalmente, estos sistemas se dicen *Basados en memoria* (*Memory based*), o dicho de otra forma, necesitan tener en memoria los intereses de todos los usuarios para emitir una recomendación. Un ejemplo de esto es el algoritmo de $$ k $$ vecinos cercanos o **KNN** (*K Nearest Neighbors*).

La idea de KNN es, en términos simples:

> Para un subconjunto de usuarios $$ \mathcal{U} \in U $$, encuentra los ratings para un item $$ i \in I $$ sobre los primeros $$ k $$ usuarios (vecinos en este contexto) que sean *objetivamente* similares a un usuario $$ u \in \mathcal{U} $$.

Lo de *objetivo* requiere atención. Entonces, ¿Cómo logramos evaluar una similitud *objetivamente*?. Medimos la distancia entre dos objetos y vemos si la distancia es lo suficientemente pequeña. Eso en términos simples.

Ahora, con otra alguna definición *algo más rigurosa*, decimos que la *recomendación* es la suma ponderada de los *ratings* de otros $$ k $$ usuarios sobre el mismo ítem

$$ R(u,i) = \bar{r}_u + \alpha \sum_{j=1}^{k} w(u,j)(r_{j,i}-\bar{r}_j) $$

donde $$ \alpha $$ es un elemento de *regularización*, $$ \bar{r}_u $$ es el promedio de votos del usuario $$ u $$, $$ (r_{j,i}-\bar{r}_j) $$ es el voto de cada usuario o vecino sobre el ítem $$ i $$ menos el promedio de sus votos, y $$ w(u,j) $$ es una función que asigna un peso a cada una de estas valoraciones. Algunas variaciones de  $$ w $$ incluyen la clásica distancia Euclidiana, *Correlación de Pearson* o *Similitud coseno* (Más sobre esto adelante).

Aún así estos modelos sufren de sus propios problemas. El principal problema es de que el cálculo de cada *recomendación* requiere recorrer todos los usuarios en $$ \mathcal{U} $$ cada vez para poder establecer la vecindad de $$u$$. Esto es costoso, y asumiendo que se requiere almacenar en memoria todas las distancias o valores de $$w$$, este algoritmo se vuelve difícil de escalar. 

Además, para modelos más complejos en que la preferencia de cada usuario sobre algún ítem se modela sobre varios parámetros, ocurre algo que se llama la dimensión de la dimensionalidad (Más en el anexo).

Otro problema se debe además a la naturaleza dispersa de los datos, debido a que no todos estamos votando por todo constantemente en internet. Hay muchas columnas vacías, lo que le da menos densidad al perfil de usuario, lo que se transforma en una probabilidad menor de encontrar gustos similares con otros usuarios.

*Otro problema* también ocurre cuando agregamos un nuevo ítem a nuestro SR. Nadie ha votado por él. *¿Cómo sabemos a quién recomendárselo?*. 

Algunas de las soluciones posibles en términos de escalabilidad y dispersión de los datos es la de reducir la dimensionalidad de estos, comprimiendo el espacio de búsqueda en uno más denso. Algunos ejemplos son *Similarity indexing*, *offline clustering* o *PCA, principal component analysis*. 

Otras solución apunta al filtrado colaborativo en **base a ítems**, a diferencia del basado en usuarios como el comentado aquí. Más de eso en el siguiente post.

## Anexo: Curse of dimensionality

![curse-of-dimenzinality]({{ "/assets/curse-of-dimensionality.png" | absolute_url }} "omg" )

Básicamente se trata de lo siguiente: Mientras más características tengan los vectores usados en la modelación de un ítem o recomendación, la distancia entre dos elementos **pierde significancia**.

Suponiendo un espacio de características de $$ d $$ dimensiones se tiene que la proporción entre la distancia de cualquier punto dentro de ese espacio hacia el centroide de dicho espacio (o donde se concentra la mayor cantidad de elementos) y hacia otro punto (el que queremos comparar) dentro del mismo espacio se diluye a $$0$$ *en el infinito*. 

$$\lim_{d\to\infty} \frac{\mbox{dist}_{\mbox{max}}-\mbox{dist}_{\mbox{min}}}{\mbox{dist}_{\mbox{min}}} \to 0$$

Esto debido a cómo se distribuyen los elementos dentro de un *hipercubo* de $$ d $$ dimensiones, y su *hiperesfera*  inscrita.	

[Este blog](https://erikbern.com/2015/10/20/nearest-neighbors-and-vector-models-epilogue-curse-of-dimensionality.html) tiene más información al respecto de esto ~~además de ahorrarme el tiempo de hacer mi propia imagen.~~ [Este otro post](http://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/) presenta una explicación más detallada, *que también incluye perritos.*

{: style="text-align:center"}
![curse-of-dimenzinality]({{ "/assets/3Dproblem_separated.png" | absolute_url }} "omg, 3D" )


# A continuación
*  *Item based collaborative filtering* en vez de *User based*
*  Estrategias para evaluar similitud en palabras y elementos
