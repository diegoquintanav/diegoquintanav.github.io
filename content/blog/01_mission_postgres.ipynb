{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#About\" data-toc-modified-id=\"About-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>About</a></span></li><li><span><a href=\"#Postgres-Mission\" data-toc-modified-id=\"Postgres-Mission-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Postgres Mission</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-the-postgres-instance\" data-toc-modified-id=\"Create-the-postgres-instance-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Create the postgres instance</a></span></li></ul></li><li><span><a href=\"#Create-users-and-roles\" data-toc-modified-id=\"Create-users-and-roles-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Create users and roles</a></span></li><li><span><a href=\"#Preparing-for-data-insertion\" data-toc-modified-id=\"Preparing-for-data-insertion-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Preparing for data insertion</a></span><ul class=\"toc-item\"><li><span><a href=\"#Inspection-of-the-data\" data-toc-modified-id=\"Inspection-of-the-data-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Inspection of the data</a></span></li><li><span><a href=\"#Shaping-data\" data-toc-modified-id=\"Shaping-data-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Shaping data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Clean-missing-values\" data-toc-modified-id=\"Clean-missing-values-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Clean missing values</a></span></li><li><span><a href=\"#Merge-date-columns-into-a-single-one\" data-toc-modified-id=\"Merge-date-columns-into-a-single-one-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Merge date columns into a single one</a></span></li><li><span><a href=\"#Further-optimizations\" data-toc-modified-id=\"Further-optimizations-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>Further optimizations</a></span></li></ul></li><li><span><a href=\"#Creating-the-table-with-SQL\" data-toc-modified-id=\"Creating-the-table-with-SQL-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Creating the table with SQL</a></span></li><li><span><a href=\"#Insert-the-data-in-the-database\" data-toc-modified-id=\"Insert-the-data-in-the-database-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Insert the data in the database</a></span></li></ul></li><li><span><a href=\"#Grant-specific-privileges-between-users-and-tables\" data-toc-modified-id=\"Grant-specific-privileges-between-users-and-tables-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Grant specific privileges between users and tables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Verify-permissions-and-roles\" data-toc-modified-id=\"Verify-permissions-and-roles-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Verify permissions and roles</a></span><ul class=\"toc-item\"><li><span><a href=\"#As-postgres-user\" data-toc-modified-id=\"As-postgres-user-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>As <code>postgres</code> user</a></span></li><li><span><a href=\"#As-data_prod_user\" data-toc-modified-id=\"As-data_prod_user-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>As <code>data_prod_user</code></a></span></li><li><span><a href=\"#Checking-permissions-as-analyst1\" data-toc-modified-id=\"Checking-permissions-as-analyst1-5.1.3\"><span class=\"toc-item-num\">5.1.3&nbsp;&nbsp;</span>Checking permissions as <code>analyst1</code></a></span></li></ul></li></ul></li><li><span><a href=\"#Final-words\" data-toc-modified-id=\"Final-words-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Final words</a></span></li><li><span><a href=\"#Moving-forward\" data-toc-modified-id=\"Moving-forward-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Moving forward</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This is the notebook I created to solve the first mission in the _data engineering path_ in [dataquest.io](www.dataquest.io). I am also experimenting with the [Pelican-Jupyter Notebook](https://github.com/danielfrg/pelican-ipynb) extension, that allows to load jupyter notebooks directly in the blog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postgres Mission\n",
    "\n",
    "The problem goes something like this:\n",
    "\n",
    "> Recently, the International Hurricane Watchgroup (IHW) has been asked to update their analysis tools. Because of the increase in public awareness of hurricanes, they are required to be more diligient with the analysis of historical hurricane data they share across the organization. They have asked you, someone with experience in databases, to help work with their team to productionize their services.\n",
    "> \n",
    "> Accepting the job, their team tells you that they have been having trouble sharing data across the teams and keeping it consistent. From what they've told you, it seems that their method of sharing the data with their data anaylsts has been to save a CSV file on their local servers and have every data analyst pull the data down. Then, each analyst uses a local SQLite engine to store the CSV, run their queries, and send their results around.\n",
    ">\n",
    "> From what they have told you, you might be thinking that this is an inefficient way of sharing data. To understand what you will be working on, they have sent you a CSV file. Their CSV file contains the following fields:\n",
    ">\n",
    ">     fid - ID for the row\n",
    ">     year - Recorded year\n",
    ">     month - Recorded month\n",
    ">     day - Recorded date\n",
    ">     ad_time - Recorded time in UTC\n",
    ">     btid - Hurricane ID\n",
    ">     name - Name of the hurricane\n",
    ">     lat - Latitude of the recorded location\n",
    ">     long - Longitude of the recorded location\n",
    ">     wind_kts - Wind speed in knots per second\n",
    ">     pressure - Atmospheric pressure of the hurricane\n",
    ">     cat - Hurricane category\n",
    ">     basin - The basin the hurricane is located\n",
    ">     shape_leng - Hurricane shape length\n",
    ">\n",
    "> In this Guided Project, you will be using the local installed version of Postgres you installed from the previous project. This is much different than previous Guided Projects as you will be using your own notebook and your own Python environment instead of Dataquest's. Your job is to show that you can create a database that will accomplish the following requirements:\n",
    ">\n",
    ">    1. Database for the IHW to store their tables.\n",
    ">    2. Table that contains the fields detailed in the CSV file\n",
    ">    3. User that can update, read, and insert into a table of the data.\n",
    ">    4. Insert the data into the table.\n",
    "\n",
    "Let's do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the postgres instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using a docker container with a postgres persistent database. The `pgadmin` instance is not needed, but we can use it to have a GUI available by default in `0.0.0.0:8080`. Note this is a toy configuration, and it should not be used to store sensitive information.\n",
    "\n",
    "We won't be dealing with what this file means. Here we use docker to have a disposable database quickly. You could have a local postgres instance and that would work as well.\n",
    "\n",
    "You can get more information about postgres in docker in the [docker store](https://store.docker.com/_/postgres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Use postgres/example user/password credentials\r\n",
      "version: '3.1'\r\n",
      "\r\n",
      "services:\r\n",
      "  db:\r\n",
      "    image: postgres:10\r\n",
      "    environment:\r\n",
      "      POSTGRES_USER: postgres\r\n",
      "      POSTGRES_PASSWORD: postgres \r\n",
      "    volumes:\r\n",
      "      - pgdata:/var/lib/postgresql/data\r\n",
      "    ports:\r\n",
      "      - 54320:5432\r\n",
      "    networks:\r\n",
      "      db_nw:\r\n",
      "        aliases:\r\n",
      "          - postgres\r\n",
      "  pgadmin:\r\n",
      "    image: dpage/pgadmin4:latest\r\n",
      "    environment:\r\n",
      "      POSTGRES_PASSWORD: postgres \r\n",
      "      PGADMIN_DEFAULT_EMAIL: user@domain.com \r\n",
      "      PGADMIN_DEFAULT_PASSWORD: admin\r\n",
      "    ports:\r\n",
      "      - 8080:80\r\n",
      "    networks:\r\n",
      "      - db_nw\r\n",
      "\r\n",
      "volumes:\r\n",
      "    pgdata: {}\r\n",
      "\r\n",
      "networks:\r\n",
      "  db_nw:\r\n",
      "    driver: bridge\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat docker-compose.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dq_de_db_1 is up-to-date\r\n",
      "dq_de_pgadmin_1 is up-to-date\r\n"
     ]
    }
   ],
   "source": [
    "!docker-compose -p dq_de up -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE                                   COMMAND                  CREATED             STATUS              PORTS                           NAMES\r\n",
      "58b58e1f97f4        postgres:10                             \"docker-entrypoint.sâ€¦\"   10 days ago         Up 3 hours          0.0.0.0:54320->5432/tcp         dq_de_db_1\r\n",
      "c5b7c0ec8430        dpage/pgadmin4:latest                   \"/entrypoint.sh\"         10 days ago         Up 3 hours          443/tcp, 0.0.0.0:8080->80/tcp   dq_de_pgadmin_1\r\n",
      "9f18df162b11        rediscommander/redis-commander:latest   \"/usr/bin/dumb-init â€¦\"   2 weeks ago         Up 3 hours          0.0.0.0:8081->8081/tcp          redis-commander\r\n",
      "e38a793b3b60        postgres:10                             \"docker-entrypoint.sâ€¦\"   2 weeks ago         Up 3 hours          0.0.0.0:51085->5432/tcp         demo_db_1\r\n"
     ]
    }
   ],
   "source": [
    "# check if postgres docker instance is alive\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            \"SecondaryIPAddresses\": null,\r\n",
      "            \"IPAddress\": \"\",\r\n",
      "                    \"IPAddress\": \"192.168.32.3\",\r\n"
     ]
    }
   ],
   "source": [
    "# retrieve the ip address of the container, seen from the host\n",
    "!docker inspect dq_de_db_1 | grep \"IPAddress\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we could also refer to our database by the port mapping done in the `docker-compose.yml` file. This means that we could reach our database in `0.0.0.0:54320`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create users and roles\n",
    "\n",
    "The mission instructions state that\n",
    "\n",
    "> With a table set up, it's now time to create a user on the Postgres database that can insert, update, and read the data but not delete. This is to make sure that someone who might get a hold of this user does not issue a destructive command. Essentially, this is like creating a \"data production\" user whose job it is is to always write new and existing data to the table.\n",
    "> \n",
    "> Futhermore, even though it wasn't according to the spec, we know that the IHW team's analysts just run read queries on the data. Also, since the analysts only know SQLite queries, they may not be well-versed in a production database. As such, it might be risky handing out a general production user for them to query their data.\n",
    "> \n",
    "> From what you have learned about security and restricting well meaning users, it might be a good idea to restrict those analysts from some commands. Those commands can be anything from adding new data to the table or changing the values. You should decide what commands should be given to the analyst user.\n",
    "\n",
    "In short, what I get from this is\n",
    "\n",
    "*  Connected as a `postgres` user, create a user `data_prod_user` that can insert, update, and read the data but **not** delete.\n",
    "*  This is like a \"data production\" user whose job is to always write new and existing data to the table.\n",
    "\n",
    "Also,\n",
    "\n",
    "*  Create a role `GROUP` for the IHW analyst team that can only read data from tables\n",
    "*  Create a user in this group, called `analyst1`. Picking names is _hard_\n",
    "\n",
    "Note that _users_ and _groups_ are all part of the same entity in postgres, the [_role_](https://severalnines.com/blog/postgresql-privileges-user-management-what-you-should-know).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/.pyenv/versions/3.6.6/envs/dq-de/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE DATABASE ihw OWNER postgres\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"postgres\", user=\"postgres\", password=\"postgres\", host=\"192.168.32.3\"\n",
    ")\n",
    "\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "DATA_PROD_USER_PWD = \"changeme\"\n",
    "DATA_VIEW_USER_PWD = \"changeme\"\n",
    "\n",
    "# create user and detach password from command\n",
    "# also add an IF NOT EXIST clause as a hack from\n",
    "# https://stackoverflow.com/questions/8092086/create-postgresql-role-user-if-it-doesnt-exist\n",
    "cur.execute(f\"\"\"\n",
    "CREATE USER data_prod_user WITH PASSWORD '{DATA_PROD_USER_PWD}';\n",
    "CREATE GROUP readonly WITH NOLOGIN;\n",
    "CREATE USER analyst1 WITH PASSWORD '{DATA_VIEW_USER_PWD}' IN GROUP readonly;\n",
    "\"\"\")\n",
    "\n",
    "# create db\n",
    "print(\"CREATE DATABASE ihw OWNER postgres\")\n",
    "cur.execute(\"CREATE DATABASE ihw OWNER postgres\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to start over, just `DROP` everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revoke all permissions by default. \n",
    "# Use this to start all over.\n",
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"postgres\", user=\"postgres\", password=\"postgres\", host=\"192.168.32.3\"\n",
    ")\n",
    "\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "# drop users\n",
    "cur.execute(\"\"\"\n",
    "DROP USER data_prod_user;\n",
    "DROP USER analyst1;\n",
    "DROP GROUP readonly;\n",
    "\"\"\")\n",
    "\n",
    "# drop db\n",
    "print(\"DROP DATABASE IF EXISTS ihw\")\n",
    "cur.execute(\"DROP DATABASE IF EXISTS ihw\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing for data insertion\n",
    "\n",
    "\n",
    "Now with our new users, we can start creating our tables. A table is assigned by default to the user that created it, and it will live by default in the database that the connection was assigned to.\n",
    "\n",
    "The steps involved in inserting the data are\n",
    "\n",
    "1. Inspect the data: This process is specific to the problem, and it may vary each time. I will be using `pandas`\n",
    "2. Infer the data types from the previous analysis that will be used in out SQL table: This refers to the questions of the type _\"would an integer suffice?\", \"how long should these strings be\", \"Can this column be normalized?\"_. This will probably require shaping the data analyzed previously.\n",
    "3. Create the table: This is the translation of the previous step into a proper SQL table.\n",
    "4. Populate the table: Fill the new table with data. I will be using postgres' `COPY` feature by means of `psycopg.copy_expert()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection of the data\n",
    "\n",
    "Before even knowing how our table will should be created, we should inspect our data. We will be using `pandas` for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>AD_TIME</th>\n",
       "      <th>BTID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG</th>\n",
       "      <th>WIND_KTS</th>\n",
       "      <th>PRESSURE</th>\n",
       "      <th>CAT</th>\n",
       "      <th>BASIN</th>\n",
       "      <th>Shape_Leng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>1957</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1800Z</td>\n",
       "      <td>63</td>\n",
       "      <td>NOTNAMED</td>\n",
       "      <td>22.5</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>1.140175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>1961</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1200Z</td>\n",
       "      <td>116</td>\n",
       "      <td>PAULINE</td>\n",
       "      <td>22.1</td>\n",
       "      <td>-140.2</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>1.166190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>1962</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>0600Z</td>\n",
       "      <td>124</td>\n",
       "      <td>C</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>2.102380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>1967</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0600Z</td>\n",
       "      <td>168</td>\n",
       "      <td>DENISE</td>\n",
       "      <td>16.6</td>\n",
       "      <td>-139.5</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>2.121320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>1972</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1200Z</td>\n",
       "      <td>251</td>\n",
       "      <td>DIANA</td>\n",
       "      <td>18.5</td>\n",
       "      <td>-139.8</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>H1</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>1.702939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FID  YEAR  MONTH  DAY AD_TIME  BTID      NAME   LAT   LONG  WIND_KTS  \\\n",
       "0  2001  1957      8    8   1800Z    63  NOTNAMED  22.5 -140.0        50   \n",
       "1  2002  1961     10    3   1200Z   116   PAULINE  22.1 -140.2        45   \n",
       "2  2003  1962      8   29   0600Z   124         C  18.0 -140.0        45   \n",
       "3  2004  1967      7   14   0600Z   168    DENISE  16.6 -139.5        45   \n",
       "4  2005  1972      8   16   1200Z   251     DIANA  18.5 -139.8        70   \n",
       "\n",
       "   PRESSURE CAT            BASIN  Shape_Leng  \n",
       "0         0  TS  Eastern Pacific    1.140175  \n",
       "1         0  TS  Eastern Pacific    1.166190  \n",
       "2         0  TS  Eastern Pacific    2.102380  \n",
       "3         0  TS  Eastern Pacific    2.121320  \n",
       "4         0  H1  Eastern Pacific    1.702939  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://dq-content.s3.amazonaws.com/251/storm_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59228 entries, 0 to 59227\n",
      "Data columns (total 14 columns):\n",
      "FID           59228 non-null int64\n",
      "YEAR          59228 non-null int64\n",
      "MONTH         59228 non-null int64\n",
      "DAY           59228 non-null int64\n",
      "AD_TIME       59228 non-null object\n",
      "BTID          59228 non-null int64\n",
      "NAME          59228 non-null object\n",
      "LAT           59228 non-null float64\n",
      "LONG          59228 non-null float64\n",
      "WIND_KTS      59228 non-null int64\n",
      "PRESSURE      59228 non-null int64\n",
      "CAT           59228 non-null object\n",
      "BASIN         59228 non-null object\n",
      "Shape_Leng    59228 non-null float64\n",
      "dtypes: float64(3), int64(7), object(4)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>BTID</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG</th>\n",
       "      <th>WIND_KTS</th>\n",
       "      <th>PRESSURE</th>\n",
       "      <th>Shape_Leng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59228.000000</td>\n",
       "      <td>59228.000000</td>\n",
       "      <td>59228.000000</td>\n",
       "      <td>59228.000000</td>\n",
       "      <td>59228.000000</td>\n",
       "      <td>59228.000000</td>\n",
       "      <td>59228.000000</td>\n",
       "      <td>59228.000000</td>\n",
       "      <td>59228.000000</td>\n",
       "      <td>59228.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29614.500000</td>\n",
       "      <td>1957.194874</td>\n",
       "      <td>8.540521</td>\n",
       "      <td>15.867326</td>\n",
       "      <td>648.398899</td>\n",
       "      <td>23.526400</td>\n",
       "      <td>-83.196863</td>\n",
       "      <td>54.726802</td>\n",
       "      <td>372.336800</td>\n",
       "      <td>1.201987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17097.795209</td>\n",
       "      <td>41.665792</td>\n",
       "      <td>1.364174</td>\n",
       "      <td>8.793432</td>\n",
       "      <td>372.376803</td>\n",
       "      <td>9.464955</td>\n",
       "      <td>37.282152</td>\n",
       "      <td>25.133577</td>\n",
       "      <td>480.562974</td>\n",
       "      <td>0.834497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1851.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>-180.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14807.750000</td>\n",
       "      <td>1928.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>-108.500000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29614.500000</td>\n",
       "      <td>1970.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>606.000000</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>-81.200000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.029563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44421.250000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>920.000000</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>-62.200000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>1.431782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59228.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1410.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>11.180340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                FID          YEAR         MONTH           DAY          BTID  \\\n",
       "count  59228.000000  59228.000000  59228.000000  59228.000000  59228.000000   \n",
       "mean   29614.500000   1957.194874      8.540521     15.867326    648.398899   \n",
       "std    17097.795209     41.665792      1.364174      8.793432    372.376803   \n",
       "min        1.000000   1851.000000      1.000000      1.000000      1.000000   \n",
       "25%    14807.750000   1928.000000      8.000000      8.000000    344.000000   \n",
       "50%    29614.500000   1970.000000      9.000000     16.000000    606.000000   \n",
       "75%    44421.250000   1991.000000      9.000000     23.000000    920.000000   \n",
       "max    59228.000000   2008.000000     12.000000     31.000000   1410.000000   \n",
       "\n",
       "                LAT          LONG      WIND_KTS      PRESSURE    Shape_Leng  \n",
       "count  59228.000000  59228.000000  59228.000000  59228.000000  59228.000000  \n",
       "mean      23.526400    -83.196863     54.726802    372.336800      1.201987  \n",
       "std        9.464955     37.282152     25.133577    480.562974      0.834497  \n",
       "min        4.200000   -180.000000     10.000000      0.000000      0.000000  \n",
       "25%       16.100000   -108.500000     35.000000      0.000000      0.707107  \n",
       "50%       21.200000    -81.200000     50.000000      0.000000      1.029563  \n",
       "75%       29.600000    -62.200000     70.000000    990.000000      1.431782  \n",
       "max       69.000000    180.000000    165.000000   1024.000000     11.180340  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, we have some guidelines from dataquest of how the table should look like:\n",
    "\n",
    "- `fid` is an INT and should be a `PRIMARY KEY`\n",
    "- `YEAR, MONTH, DAY` and `AD_TIME` should be merged into one single `TIMESTAMP`, using `TIME ZONE`.\n",
    "- `btid` looks like an `INT`\n",
    "- We have no way of knowing how long a `name` can be, thus we will be using a `VARCHAR`\n",
    "- `lat` is of type `DECIMAL(X,Y)`. We need to figure out `X` and `Y`\n",
    "- `long` is of type `DECIMAL(X,Y)`, We also need to figure out `X` and `Y`\n",
    "- `wind_kts` looks like an `INT`\n",
    "- `pressure` looks like an `INT`\n",
    "- `cat` looks like a categorical value, kinda like a `VARCHAR(X)`. We need to figure out `X`\n",
    "- `basin` is a `VARCHAR(X)`. Same as `cat`\n",
    "- `shape_length` looks like a `DECIMAL(X, Y)`\n",
    "\n",
    "The next step is figuring out some variables, like\n",
    "- The values of `X` and `Y` in `VARCHAR` and `DECIMAL`\n",
    "- The maximum values of those columns that look like integers. With this we could use even smaller datatypes like `SMALLINT` and others.\n",
    "\n",
    "We can infer most of these values through inspection of the `min` and `max` values in `df.describe()`. We could then produce a table like this:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE hurricanes (\n",
    "    fid INT PRIMARY KEY,\n",
    "    timestamp TIMESTAMP WITH TIME ZONE,\n",
    "    btid SMALLINT,\n",
    "    name VARCHAR,\n",
    "    lat DECIMAL(8,6),\n",
    "    long DECIMAL(9,6),\n",
    "    wind_kts SMALLINT,\n",
    "    pressure SMALLINT,\n",
    "    cat VARCHAR(X),\n",
    "    basin VARCHAR(X),\n",
    "    shape_length DECIMAL(8, 6)\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can infer the values of `X` in `VARCHAR(X)` by doing something like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BASIN'].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CAT'].str.len().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that these columns are maximum 15 and 2 characters long. Out table will end looking like\n",
    "\n",
    "```sql\n",
    "CREATE TABLE hurricanes (\n",
    "    fid INT PRIMARY KEY,\n",
    "    timestamp TIMESTAMP WITH TIME ZONE,\n",
    "    btid SMALLINT,\n",
    "    name VARCHAR,\n",
    "    lat DECIMAL(8,6),\n",
    "    long DECIMAL(9,6),\n",
    "    wind_kts SMALLINT,\n",
    "    pressure SMALLINT,\n",
    "    cat VARCHAR(2),\n",
    "    basin VARCHAR(15),\n",
    "    shape_length DECIMAL(8, 6)\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shaping data\n",
    "From here, we need to \n",
    "0. Clean and check for possible missing values\n",
    "1. Merge `year`, `month`, `day` and `ad_time` into one column named `timestamp`\n",
    "\n",
    "Possible optimizations are\n",
    "1. Using label encoding in categorical columns\n",
    "2. Use better datatypes for specific purposes, like georeferenced values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FID           0\n",
       "YEAR          0\n",
       "MONTH         0\n",
       "DAY           0\n",
       "AD_TIME       0\n",
       "BTID          0\n",
       "NAME          0\n",
       "LAT           0\n",
       "LONG          0\n",
       "WIND_KTS      0\n",
       "PRESSURE      0\n",
       "CAT           0\n",
       "BASIN         0\n",
       "Shape_Leng    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total na numbers\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FID           0\n",
       "YEAR          0\n",
       "MONTH         0\n",
       "DAY           0\n",
       "AD_TIME       0\n",
       "BTID          0\n",
       "NAME          0\n",
       "LAT           0\n",
       "LONG          0\n",
       "WIND_KTS      0\n",
       "PRESSURE      0\n",
       "CAT           0\n",
       "BASIN         0\n",
       "Shape_Leng    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, not so much to do here ðŸ˜Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge date columns into a single one\n",
    "\n",
    "We'll be using `pd.to_datetime` from https://pandas.pydata.org/pandas-docs/stable/generated/pandas.to_datetime.html\n",
    "\n",
    "1. We'll need to convert AD_TIME from the current format to a valid datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1800Z\n",
       "1    1200Z\n",
       "2    0600Z\n",
       "3    0600Z\n",
       "4    1200Z\n",
       "Name: AD_TIME, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AD_TIME'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We join everything together in one column, as a dumb string. This is to make the conversion easier afterwards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TIMESTAMP'] = df['YEAR'].astype(str) + \\\n",
    "                  df['MONTH'].astype(str).str.zfill(2) + \\\n",
    "                  df['DAY'].astype(str).str.zfill(2) + \\\n",
    "                  df['AD_TIME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    195708081800Z\n",
       "1    196110031200Z\n",
       "2    196208290600Z\n",
       "3    196707140600Z\n",
       "4    197208161200Z\n",
       "Name: TIMESTAMP, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TIMESTAMP'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the dumb string column to a valid timestamp object, and we pass a format and we tell pandas that the time is in UTC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'], format='%Y%m%d%H%MZ', utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   1957-08-08 18:00:00+00:00\n",
       "1   1961-10-03 12:00:00+00:00\n",
       "2   1962-08-29 06:00:00+00:00\n",
       "3   1967-07-14 06:00:00+00:00\n",
       "4   1972-08-16 12:00:00+00:00\n",
       "Name: TIMESTAMP, dtype: datetime64[ns, UTC]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TIMESTAMP'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the other columns associated with time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['YEAR','MONTH','DAY','AD_TIME'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>BTID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG</th>\n",
       "      <th>WIND_KTS</th>\n",
       "      <th>PRESSURE</th>\n",
       "      <th>CAT</th>\n",
       "      <th>BASIN</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>63</td>\n",
       "      <td>NOTNAMED</td>\n",
       "      <td>22.5</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>1.140175</td>\n",
       "      <td>1957-08-08 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>116</td>\n",
       "      <td>PAULINE</td>\n",
       "      <td>22.1</td>\n",
       "      <td>-140.2</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>1.166190</td>\n",
       "      <td>1961-10-03 12:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>124</td>\n",
       "      <td>C</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>2.102380</td>\n",
       "      <td>1962-08-29 06:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>168</td>\n",
       "      <td>DENISE</td>\n",
       "      <td>16.6</td>\n",
       "      <td>-139.5</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>1967-07-14 06:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>251</td>\n",
       "      <td>DIANA</td>\n",
       "      <td>18.5</td>\n",
       "      <td>-139.8</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>H1</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>1.702939</td>\n",
       "      <td>1972-08-16 12:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FID  BTID      NAME   LAT   LONG  WIND_KTS  PRESSURE CAT            BASIN  \\\n",
       "0  2001    63  NOTNAMED  22.5 -140.0        50         0  TS  Eastern Pacific   \n",
       "1  2002   116   PAULINE  22.1 -140.2        45         0  TS  Eastern Pacific   \n",
       "2  2003   124         C  18.0 -140.0        45         0  TS  Eastern Pacific   \n",
       "3  2004   168    DENISE  16.6 -139.5        45         0  TS  Eastern Pacific   \n",
       "4  2005   251     DIANA  18.5 -139.8        70         0  H1  Eastern Pacific   \n",
       "\n",
       "   Shape_Leng                 TIMESTAMP  \n",
       "0    1.140175 1957-08-08 18:00:00+00:00  \n",
       "1    1.166190 1961-10-03 12:00:00+00:00  \n",
       "2    2.102380 1962-08-29 06:00:00+00:00  \n",
       "3    2.121320 1967-07-14 06:00:00+00:00  \n",
       "4    1.702939 1972-08-16 12:00:00+00:00  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further optimizations\n",
    "\n",
    "These are valid for those columns that are clearly categorical, `CAT` and `BASIN`. We could encode this columns using _label encoding_ which would allow us to store integers instead of long strings. \n",
    "\n",
    "We could create another table that stores the meanings of the codes, this is more or less called a _one to one_ relationship and it is discussed in here\n",
    "\n",
    "- https://stackoverflow.com/questions/12318870/when-i-should-use-one-to-one-relationship\n",
    "- and here https://www.postgresql.org/message-id/flat/BB6A4899.9385D%25soft%40bdanube.com\n",
    "\n",
    "The pros and cons of this approach are \n",
    "\n",
    "Pros\n",
    "- It's more efficient to store and query integer values\n",
    "- We could create auxiliar tables that map the labels to their meanings, thus allowing for more atomic queries\n",
    "- This would allow for good normalizations practices that will help in scaling our database (and keeping it sane to maintain)\n",
    "\n",
    "Cons\n",
    "- Integers lose any semantic meaning without a conversion table\n",
    "- Adding semantic meaning from an auxiliar table requires a `JOIN` operation, which is costly\n",
    "- It requires a bit more of effort\n",
    "- It could happen that the column is not categorical at all (i.e. more different values for BASIN show up in the future) \n",
    "\n",
    "We will not use this approach since it beats the purpose of the problem, and for this case is overkill since each category does not have or need a full model by itself, since it would consist of only one attribute. We'll keep it simple.\n",
    "\n",
    "[This Stackoverflow question](https://dba.stackexchange.com/a/15405) deals with normalization on _one-to-one_ relationships:\n",
    "\n",
    "\n",
    "> If it fits within the rules of normalization, then 1:1 relationships can be normalized (by definition!) - In other words, there is nothing about 1:1 relationships that make it impossible for them to obey the normal forms.\n",
    ">\n",
    "> To answer your question about the practicality of 1:1 relationships, there are times when this is a perfectly useful construct, such as when you have subtypes with distinct predicates (columns).\n",
    ">\n",
    "> The reasons you would use 1:1 relationships depend on your point of view. DBAs tend to think of everything as being a performance decision. Data modelers and programmers tend to think of these decisions as being design or model oriented. In fact, there is a lot of overlap between these points of view. It depends on what your perspectives and priorities are. Here are some examples of motivations for 1:1 relationships:\n",
    "\n",
    ">   - You have some subset of columns that are very wide and you want to segregate them physically in your storage for performance reasons.\n",
    ">\n",
    ">   - You have some subset of columns that are not read or updated frequently and you want to keep them apart from the frequently used columns for performance reasons.\n",
    ">\n",
    ">   - You have some columns that are optional in general but they are mandatory when you know that the record is of a certain type.\n",
    ">\n",
    ">   - You have some columns that logically belong together for a subtype and you want to model them to fit well with your code's object model.\n",
    ">\n",
    ">   - You have some columns that can only apply to some subtype(s) of an entity super-type, and you want your schema to enforce the absence of this data for other subtypes.\n",
    ">\n",
    ">   - You have some columns that belong to an entity but you need to protect these particular columns using more restrictive access rules (e.g. salary on an employee table).\n",
    ">\n",
    "> So you can see, sometimes the driver is performance, sometimes it is model purity, or just a desire to take full advantage of declarative schema rules.\n",
    "\n",
    "\n",
    "\n",
    "We could even push this further and say that the `BASIN` column is more of a _boolean_ value since it has two values max. This allows us to rewrite the column in something like `IS_BASIN_EASTERN_PACIFIC`. We could say then that for those values where this is `False` then it means the Basin it's `North Atlantic`. \n",
    "\n",
    "But this is _never_ a good approach since it uses this information implicitly (thus hidden, and we don't want hidden stuff!), plus this will break the second a new category shows up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BASIN'].astype('category').cat.codes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  1,  9,  3,  2,  6,  4,  5,  0, 11,  8,  7])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CAT'].astype('category').cat.codes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>BTID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG</th>\n",
       "      <th>WIND_KTS</th>\n",
       "      <th>PRESSURE</th>\n",
       "      <th>CAT</th>\n",
       "      <th>BASIN</th>\n",
       "      <th>SHAPE_LENG</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>63</td>\n",
       "      <td>NOTNAMED</td>\n",
       "      <td>22.5</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>1.140175</td>\n",
       "      <td>1957-08-08 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>116</td>\n",
       "      <td>PAULINE</td>\n",
       "      <td>22.1</td>\n",
       "      <td>-140.2</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>1.166190</td>\n",
       "      <td>1961-10-03 12:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>124</td>\n",
       "      <td>C</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>2.102380</td>\n",
       "      <td>1962-08-29 06:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>168</td>\n",
       "      <td>DENISE</td>\n",
       "      <td>16.6</td>\n",
       "      <td>-139.5</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>1967-07-14 06:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>251</td>\n",
       "      <td>DIANA</td>\n",
       "      <td>18.5</td>\n",
       "      <td>-139.8</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>H1</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>1.702939</td>\n",
       "      <td>1972-08-16 12:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FID  BTID      NAME   LAT   LONG  WIND_KTS  PRESSURE CAT            BASIN  \\\n",
       "0  2001    63  NOTNAMED  22.5 -140.0        50         0  TS  Eastern Pacific   \n",
       "1  2002   116   PAULINE  22.1 -140.2        45         0  TS  Eastern Pacific   \n",
       "2  2003   124         C  18.0 -140.0        45         0  TS  Eastern Pacific   \n",
       "3  2004   168    DENISE  16.6 -139.5        45         0  TS  Eastern Pacific   \n",
       "4  2005   251     DIANA  18.5 -139.8        70         0  H1  Eastern Pacific   \n",
       "\n",
       "   SHAPE_LENG                 TIMESTAMP  \n",
       "0    1.140175 1957-08-08 18:00:00+00:00  \n",
       "1    1.166190 1961-10-03 12:00:00+00:00  \n",
       "2    2.102380 1962-08-29 06:00:00+00:00  \n",
       "3    2.121320 1967-07-14 06:00:00+00:00  \n",
       "4    1.702939 1972-08-16 12:00:00+00:00  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look back at our table, and we rearrange the columns in the dataframe to match this table\n",
    "\n",
    "```sql\n",
    "fid INT PRIMARY KEY,\n",
    "timestamp TIMESTAMP WITH TIME ZONE,\n",
    "btid SMALLINT,\n",
    "name VARCHAR,\n",
    "lat DECIMAL(8,6),\n",
    "long DECIMAL(9,6),\n",
    "wind_kts SMALLINT,\n",
    "pressure SMALLINT,\n",
    "cat VARCHAR(2),\n",
    "basin VARCHAR(16),\n",
    "shape_length DECIMAL(7, 6)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>BTID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG</th>\n",
       "      <th>WIND_KTS</th>\n",
       "      <th>PRESSURE</th>\n",
       "      <th>CAT</th>\n",
       "      <th>BASIN</th>\n",
       "      <th>SHAPE_LENG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>1957-08-08 18:00:00+00:00</td>\n",
       "      <td>63</td>\n",
       "      <td>NOTNAMED</td>\n",
       "      <td>22.5</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>1.140175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>1961-10-03 12:00:00+00:00</td>\n",
       "      <td>116</td>\n",
       "      <td>PAULINE</td>\n",
       "      <td>22.1</td>\n",
       "      <td>-140.2</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>1.166190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>1962-08-29 06:00:00+00:00</td>\n",
       "      <td>124</td>\n",
       "      <td>C</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>2.102380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>1967-07-14 06:00:00+00:00</td>\n",
       "      <td>168</td>\n",
       "      <td>DENISE</td>\n",
       "      <td>16.6</td>\n",
       "      <td>-139.5</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>2.121320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>1972-08-16 12:00:00+00:00</td>\n",
       "      <td>251</td>\n",
       "      <td>DIANA</td>\n",
       "      <td>18.5</td>\n",
       "      <td>-139.8</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>H1</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>1.702939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TIMESTAMP  BTID      NAME   LAT   LONG  WIND_KTS  \\\n",
       "FID                                                                     \n",
       "2001 1957-08-08 18:00:00+00:00    63  NOTNAMED  22.5 -140.0        50   \n",
       "2002 1961-10-03 12:00:00+00:00   116   PAULINE  22.1 -140.2        45   \n",
       "2003 1962-08-29 06:00:00+00:00   124         C  18.0 -140.0        45   \n",
       "2004 1967-07-14 06:00:00+00:00   168    DENISE  16.6 -139.5        45   \n",
       "2005 1972-08-16 12:00:00+00:00   251     DIANA  18.5 -139.8        70   \n",
       "\n",
       "      PRESSURE CAT            BASIN  SHAPE_LENG  \n",
       "FID                                              \n",
       "2001         0  TS  Eastern Pacific    1.140175  \n",
       "2002         0  TS  Eastern Pacific    1.166190  \n",
       "2003         0  TS  Eastern Pacific    2.102380  \n",
       "2004         0  TS  Eastern Pacific    2.121320  \n",
       "2005         0  H1  Eastern Pacific    1.702939  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we rearrange our columns and reset the dataframe's index\n",
    "df_csv = df[['FID', 'TIMESTAMP', 'BTID', 'NAME', 'LAT', 'LONG', 'WIND_KTS', 'PRESSURE', 'CAT', 'BASIN', 'SHAPE_LENG']].copy()\n",
    "df_csv = df_csv.set_index('FID', drop=True)\n",
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll save our ammended csv somewhere else to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.to_csv(path_or_buf='data/cleaned_files.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the table with SQL\n",
    "\n",
    "Next step is _actually_ creating the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS hurricanes\n",
      "\n",
      "CREATE TABLE hurricanes (\n",
      "    fid INT PRIMARY KEY,\n",
      "    timestamp TIMESTAMP WITH TIME ZONE,\n",
      "    btid SMALLINT,\n",
      "    name VARCHAR,\n",
      "    lat DECIMAL(8,6),\n",
      "    long DECIMAL(9,6),\n",
      "    wind_kts SMALLINT,\n",
      "    pressure SMALLINT,\n",
      "    cat VARCHAR(2),\n",
      "    basin VARCHAR(16),\n",
      "    shape_length DECIMAL(8, 6)\n",
      "    )\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"ihw\", user=\"data_prod_user\", password=\"changeme\", host=\"192.168.32.3\"\n",
    ")\n",
    "\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "# year, month, day, ad_time will be stored as timestampz\n",
    "print(\"DROP TABLE IF EXISTS hurricanes\")\n",
    "cur.execute(\"DROP TABLE IF EXISTS hurricanes\")\n",
    "\n",
    "CREATE_TABLE_SQL =\"\"\"\n",
    "CREATE TABLE hurricanes (\n",
    "    fid INT PRIMARY KEY,\n",
    "    timestamp TIMESTAMP WITH TIME ZONE,\n",
    "    btid SMALLINT,\n",
    "    name VARCHAR,\n",
    "    lat DECIMAL(8,6),\n",
    "    long DECIMAL(9,6),\n",
    "    wind_kts SMALLINT,\n",
    "    pressure SMALLINT,\n",
    "    cat VARCHAR(2),\n",
    "    basin VARCHAR(16),\n",
    "    shape_length DECIMAL(8, 6)\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "print(CREATE_TABLE_SQL)\n",
    "\n",
    "cur.execute(\n",
    "    CREATE_TABLE_SQL\n",
    ")\n",
    "\n",
    "conn.commit()\n",
    "print(\"Done.\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert the data in the database\n",
    "\n",
    "Assuming we have the CSV available in disk, we can load it onto the table using `psycopg`'s `copy_expert()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"ihw\", user=\"data_prod_user\", password=\"changeme\", host=\"192.168.32.3\")\n",
    "\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "with open('data/cleaned_files.csv', 'r+') as f:\n",
    "    cur.copy_expert(\"COPY hurricanes FROM STDIN WITH CSV HEADER DELIMITER ';'\", f)\n",
    "    \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grant specific privileges between users and tables\n",
    "\n",
    "With our users and our table ready, we need to restrict the privileges some users have. This is so we can avoid unfortunate events like undesired `DELETE` or `DROP` instructions. Accidents happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"ihw\", user=\"postgres\", password=\"postgres\", host=\"192.168.32.3\"\n",
    ")\n",
    "\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "# revoke all privileges and add back specific ones\n",
    "# on user data_prod_user\n",
    "cur.execute(\"REVOKE ALL ON hurricanes FROM data_prod_user\")\n",
    "cur.execute(\"GRANT SELECT, INSERT, UPDATE ON hurricanes TO data_prod_user\")\n",
    "\n",
    "# on group readonly\n",
    "cur.execute(\"REVOKE ALL ON hurricanes FROM readonly\")\n",
    "cur.execute(\"GRANT SELECT ON hurricanes TO readonly\")\n",
    "\n",
    "conn.commit()\n",
    "print(\"Done.\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify permissions and roles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As `postgres` user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2001, datetime.datetime(1957, 8, 8, 18, 0, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 63, 'NOTNAMED', Decimal('22.500000'), Decimal('-140.000000'), 50, 0, 'TS', 'Eastern Pacific', Decimal('1.140175'))]\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"ihw\", user=\"postgres\", password=\"postgres\", host=\"192.168.32.3\"\n",
    ")\n",
    "\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "cur.execute('SELECT * FROM hurricanes LIMIT 1')\n",
    "\n",
    "print(cur.fetchall())\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As `data_prod_user`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2001,\n",
       "  datetime.datetime(1957, 8, 8, 18, 0, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)),\n",
       "  63,\n",
       "  'NOTNAMED',\n",
       "  Decimal('22.500000'),\n",
       "  Decimal('-140.000000'),\n",
       "  50,\n",
       "  0,\n",
       "  'TS',\n",
       "  'Eastern Pacific',\n",
       "  Decimal('1.140175'))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"ihw\", user=\"data_prod_user\", password=\"changeme\", host=\"192.168.32.3\"\n",
    ")\n",
    "\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('SELECT * FROM hurricanes LIMIT 1')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should be able to insert data\n",
    "cur.execute('INSERT INTO hurricanes (fid) values (1000001)')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1000001, None, None, None, None, None, None, None, None, None, None)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can read this new row from the table\n",
    "cur.execute('SELECT * FROM hurricanes WHERE fid = 1000001')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "permission denied for relation hurricanes\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-06d32ae504fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# but we should not be able to delete data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DELETE FROM hurricanes WHERE fid=1000000'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: permission denied for relation hurricanes\n"
     ]
    }
   ],
   "source": [
    "# but we should not be able to delete data\n",
    "cur.execute('DELETE FROM hurricanes WHERE fid=1000000')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"UPDATE hurricanes SET name = 'fakename' WHERE fid=1000001\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1000001, None, None, 'fakename', None, None, None, None, None, None, None)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we read the updated changes back\n",
    "cur.execute('SELECT * FROM hurricanes WHERE fid = 1000001')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking permissions as `analyst1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2001,\n",
       "  datetime.datetime(1957, 8, 8, 18, 0, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)),\n",
       "  63,\n",
       "  'NOTNAMED',\n",
       "  Decimal('22.500000'),\n",
       "  Decimal('-140.000000'),\n",
       "  50,\n",
       "  0,\n",
       "  'TS',\n",
       "  'Eastern Pacific',\n",
       "  Decimal('1.140175'))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"ihw\", user=\"analyst1\", password=\"changeme\", host=\"192.168.32.3\"\n",
    ")\n",
    "\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('SELECT * FROM hurricanes LIMIT 1')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "permission denied for relation hurricanes\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-afc5d0bde908>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# we should be able to insert data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'INSERT INTO hurricanes (fid) values (1000001)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: permission denied for relation hurricanes\n"
     ]
    }
   ],
   "source": [
    "# we should be able to insert data\n",
    "cur.execute('INSERT INTO hurricanes (fid) values (1000001)')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "permission denied for relation hurricanes\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-b52c899b5a8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UPDATE hurricanes SET name = 'fakename' WHERE fid=1000001\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: permission denied for relation hurricanes\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"UPDATE hurricanes SET name = 'fakename' WHERE fid=1000001\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "permission denied for relation hurricanes\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-06d32ae504fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# but we should not be able to delete data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DELETE FROM hurricanes WHERE fid=1000000'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: permission denied for relation hurricanes\n"
     ]
    }
   ],
   "source": [
    "# but we should not be able to delete data\n",
    "cur.execute('DELETE FROM hurricanes WHERE fid=1000000')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final words\n",
    "\n",
    "There's not so much we can say on top of what has been shown with code. We can achieve almost anything with the [`psycopg2` driver](http://initd.org/psycopg/docs/index.html), which is the most used python driver for postgres databases (their words, not mine). \n",
    "\n",
    "# Moving forward\n",
    "\n",
    "We can add another abstraction layer on top of the driver, namely an ORM or _object relational mapper_. I use [SQLAlchemy](https://www.sqlalchemy.org/) in my daily tasks and it has proven useful in many ways, but that's something for another topic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
